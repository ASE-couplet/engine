# 对于alpha模型的结果分析和beta任务分析因为发现alpha中的作诗和做对联的效果都很不理想，尤其是对联的对仗结果很差，已知的问题在于对联的现代语料数据先过了一遍诗学含英没有什么意义的处理，对于神经网络的结果，仍然需要进一步的分析和思考才能找到提升的方法。  ## 对于现代词汇到生成古诗/对联的过程和使用的词表首先是对于训练数据，使用了jieba分词，分词结果出来的词汇会通过word2vec计算其embedding，这个词汇表大概有9万左右，也包含“奥马巴”一类的若干词汇。在这个词汇表之外的词，会被直接丢掉，因为没有embedding等于完全不认识。对于输入的词汇，首先查有没有embedding，没有就丢掉。丢完如果剩4个以上的词汇，就按照在训练embedding时出现最多的顺序的前四个。少于四个，则按照embedding的近似度补足到四个。如果一个都不在词汇表中，则随机产生四个。  但是实际上，即使在词表中，结果也会不理想。因为首先，认知服务出来的词汇都是名词，而且是现代名词，很容易不在词表中出现。然后是因为训练过程中，是先使用概率转移矩阵找到每句话的主旨词，然后训练使用主旨词生成本句话。情况大致像：  >心存滴水可藏月	月  手握千金能济贫	千金  五月提前迎热浪	迎  三更依旧读寒窗	读  精进梵行身相妙	行  多闻佛法信根坚	信  君当南敌吾当北	君  气自千秋史自青	千秋  身瘦腰直蔽天下	天下  气昂体端仰玉霄	玉  紫毫粉壁题仙籍	仙  银烛金杯映翠眉	映  攻读方知书有宝	书  精研好学字当金	金  对于keyword按照次数排序并且使用jieba标注词性：  >['月', 'm', 24590]  ['春', 'tg', 23430]  ['人', 'n', 17888]  ['花', 'v', 14473]  ['风', 'n', 13761]  ['心', 'n', 13679]  ['梦', 'n', 12674]  ['诗', 'n', 11760]  ['香', 'ns', 10784]  ['水', 'n', 9346]  ['云', 'ns', 9036]  ['山', 'n', 8637]  ['春风', 'n', 8080]  ['天', 'q', 8072]  ['情', 'n', 7327]  ['雨', 'n', 7255]  ['难', 'a', 7239]  ['醉', 'v', 6996]  ['新', 'a', 6704]  ['柳', 'n', 6533]  ['酒', 'n', 6241]  ['秋', 't', 5878]  可以说，很难和识别出来的物体tag匹配上，必须要把现代词汇的tag规约到常出现的这些tag上才能有比较好的结果。而常出现的这些tag，存在的问题是不是名词，很多动词或者形容词。  需要修改的地方包括：句子产生主题词时的函数从概率矩阵修改为使用这句话中的名词；产生的tag和keyword中训练次数最多的某一数量做overlap找到keyword中的好词汇，然后在这部分中使用embedding查找相似的词汇。  ## 对联的对仗效果不好因为古诗对于对仗的要求不高，所以代码中使用的对仗是在训练embedding时产生的，其实虽然只在后面的seq2seq中也可以学到对仗，但是模型太多的注重在对主题词的合适表达而非对仗，但是这样在对联中的表现就不好，所以这部分的模型结构需要修改，打算重构成transformer的seq2seq模型，注重在seq2seq而非第二个tag的主旨。  # 任务分配1. 修改对联和古诗的每句产生主旨词的方式。任务量1天*人  2. 创建现代词汇到keyword词汇表中的对应关系。任务量1天*人3. 修改对联的seq2seq模型代码，加上transformer模型。任务量2天*人 4. 训练模型和缓冲。1天*人5. 把数据库和模型拼接到服务器上。1.5天*人6. 整理训练数据 0.5天 * 人7. 找到demo图片和产生的好古诗、好对联 0.5天*人